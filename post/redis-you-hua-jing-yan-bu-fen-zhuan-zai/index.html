<html>
  <head>
    <meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Redis优化经验(部分转载) | felayman</title>
<link rel="shortcut icon" href="https://www.felayman.com/favicon.ico?v=1635947688224">
<link href="https://cdn.jsdelivr.net/npm/remixicon@2.3.0/fonts/remixicon.css" rel="stylesheet">
<link rel="stylesheet" href="https://www.felayman.com/styles/main.css">
<link rel="alternate" type="application/atom+xml" title="Redis优化经验(部分转载) | felayman - Atom Feed" href="https://www.felayman.com/atom.xml">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Droid+Serif:400,700">



    <meta name="description" content="
redis作为一款基于内存的高性能的key-value数据库,是作为互联网中间件的一大利器,掌握Redis的基本使用以及高级特性,再懂一些优化,是面试过程中不可少的问题

前言
本文将从Redis的基本特性入手，通过讲述Redis的数据结..." />
    <meta name="keywords" content="面试" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0/katex.min.css">
    <script src="https://cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
  </head>
  <body>
    <div class="main">
      <div class="main-content">
        <div class="site-header">
  <a href="https://www.felayman.com">
  <img class="avatar" src="https://www.felayman.com/images/avatar.png?v=1635947688224" alt="">
  </a>
  <h1 class="site-title">
    felayman
  </h1>
  <p class="site-description">
    知足且上进，温柔而坚定
  </p>
  <div class="menu-container">
    
      
        <a href="/" class="menu">
          首页
        </a>
      
    
      
        <a href="/archives" class="menu">
          归档
        </a>
      
    
      
        <a href="/tags" class="menu">
          标签
        </a>
      
    
      
        <a href="/post/about" class="menu">
          关于
        </a>
      
    
  </div>
  <div class="social-container">
    
      
        <a href="https://github.com/felayman" target="_blank">
          <i class="ri-github-line"></i>
        </a>
      
    
      
    
      
    
      
    
      
    
  </div>
</div>

        <div class="post-detail">
          <article class="post">
            <h2 class="post-title">
              Redis优化经验(部分转载)
            </h2>
            <div class="post-info">
              <span>
                2016-07-21
              </span>
              <span>
                38 min read
              </span>
              
                <a href="https://www.felayman.com/tag/面试/" class="post-tag">
                  # 面试
                </a>
              
            </div>
            
            <div class="post-content-wrapper">
              <div class="post-content">
                <blockquote>
<p>redis作为一款基于内存的高性能的key-value数据库,是作为互联网中间件的一大利器,掌握Redis的基本使用以及高级特性,再懂一些优化,是面试过程中不可少的问题</p>
</blockquote>
<h2 id="前言">前言</h2>
<p>本文将从Redis的基本特性入手，通过讲述Redis的数据结构和主要命令对Redis的基本能力进行直观介绍。之后概览Redis提供的高级能力，并在部署、维护、性能调优等多个方面进行更深入的介绍和指导。<br>
本文适合使用Redis的普通开发人员，以及对Redis进行选型、架构设计和性能调优的架构设计人员。</p>
<h2 id="目录">目录</h2>
<ul>
<li>概述</li>
<li>Redis的数据结构和相关常用命令</li>
<li>数据持久化</li>
<li>内存管理与数据淘汰机制</li>
<li>Pipelining</li>
<li>事务与Scripting</li>
<li>Redis性能调优</li>
<li>主从复制与集群分片</li>
</ul>
<h3 id="概述">概述</h3>
<p>Redis是一个开源的，基于内存的结构化数据存储媒介，可以作为数据库、缓存服务或消息服务使用。</p>
<p>Redis支持多种数据结构，包括字符串、哈希表、链表、集合、有序集合、位图、Hyperloglogs等。</p>
<p>Redis具备LRU淘汰、事务实现、以及不同级别的硬盘持久化等能力，并且支持副本集和通过Redis Sentinel实现的高可用方案，同时还支持通过Redis Cluster实现的数据自动分片能力。</p>
<p>Redis的主要功能都基于单线程模型实现，也就是说Redis使用一个线程来服务所有的客户端请求，同时Redis采用了非阻塞式IO，并精细地优化各种命令的算法时间复杂度，这些信息意味着：</p>
<ul>
<li>Redis是线程安全的（因为只有一个线程），其所有操作都是原子的，不会因并发产生数据异常</li>
<li>Redis的速度非常快（因为使用非阻塞式IO，且大部分命令的算法时间复杂度都是O(1))</li>
<li>使用高耗时的Redis命令是很危险的，会占用唯一的一个线程的大量处理时间，导致所有的请求都被拖慢。（例如时间复杂度为O(N)的KEYS命令，严格禁止在生产环境中使用）</li>
</ul>
<h3 id="redis的数据结构和相关常用命令">Redis的数据结构和相关常用命令</h3>
<p>本节中将介绍Redis支持的主要数据结构，以及相关的常用Redis命令。本节只对Redis命令进行扼要的介绍，且只列出了较常用的命令。如果想要了解完整的Redis命令集，或了解某个命令的详细使用方法，请参考官方文档：https://redis.io/commands</p>
<p><strong>Key</strong></p>
<p>Redis采用Key-Value型的基本数据结构，任何二进制序列都可以作为Redis的Key使用（例如普通的字符串或一张JPEG图片）<br>
关于Key的一些注意事项：</p>
<ul>
<li>不要使用过长的Key。例如使用一个1024字节的key就不是一个好主意，不仅会消耗更多的内存，还会导致查找的效率降低</li>
<li>Key短到缺失了可读性也是不好的，例如&quot;u1000flw&quot;比起&quot;user:1000:followers&quot;来说，节省了寥寥的存储空间，却引发了可读性和可维护性上的麻烦</li>
<li>最好使用统一的规范来设计Key，比如&quot;object-type🆔attr&quot;，以这一规范设计出的Key可能是&quot;user:1000&quot;或&quot;comment🔢reply-to&quot;</li>
<li>Redis允许的最大Key长度是512MB（对Value的长度限制也是512MB）</li>
</ul>
<p><strong>String</strong></p>
<p>String是Redis的基础数据类型，Redis没有Int、Float、Boolean等数据类型的概念，所有的基本类型在Redis中都以String体现。</p>
<p>与String相关的常用命令：</p>
<ul>
<li>SET：为一个key设置value，可以配合EX/PX参数指定key的有效期，通过NX/XX参数针对key是否存在的情况进行区别操作，时间复杂度O(1)</li>
<li>GET：获取某个key对应的value，时间复杂度O(1)</li>
<li>GETSET：为一个key设置value，并返回该key的原value，时间复杂度O(1)</li>
<li>MSET：为多个key设置value，时间复杂度O(N)</li>
<li>MSETNX：同MSET，如果指定的key中有任意一个已存在，则不进行任何操作，时间复杂度O(N)</li>
<li>MGET：获取多个key对应的value，时间复杂度O(N)</li>
</ul>
<p>上文提到过，Redis的基本数据类型只有String，但Redis可以把String作为整型或浮点型数字来使用，主要体现在INCR、DECR类的命令上：</p>
<ul>
<li>INCR：将key对应的value值自增1，并返回自增后的值。只对可以转换为整型的String数据起作用。时间复杂度O(1)</li>
<li>INCRBY：将key对应的value值自增指定的整型数值，并返回自增后的值。只对可以转换为整型的String数据起作用。时间复杂度O(1)</li>
<li>DECR/DECRBY：同INCR/INCRBY，自增改为自减。</li>
</ul>
<p>INCR/DECR系列命令要求操作的value类型为String，并可以转换为64位带符号的整型数字，否则会返回错误。<br>
也就是说，进行INCR/DECR系列命令的value，必须在[-2^63 ~ 2^63 - 1]范围内。</p>
<p>前文提到过，Redis采用单线程模型，天然是线程安全的，这使得INCR/DECR命令可以非常便利的实现高并发场景下的精确控制。</p>
<p><strong>List</strong></p>
<p>Redis的List是链表型(双向链表)的数据结构，可以使用LPUSH/RPUSH/LPOP/RPOP等命令在List的两端执行插入元素和弹出元素的操作。虽然List也支持在特定index上插入和读取元素的功能，但其时间复杂度较高（O(N)），应小心使用。</p>
<p>与List相关的常用命令：</p>
<ul>
<li>LPUSH：向指定List的左侧（即头部）插入1个或多个元素，返回插入后的List长度。时间复杂度O(N)，N为插入元素的数量</li>
<li>RPUSH：同LPUSH，向指定List的右侧（即尾部）插入1或多个元素</li>
<li>LPOP：从指定List的左侧（即头部）移除一个元素并返回，时间复杂度O(1)</li>
<li>RPOP：同LPOP，从指定List的右侧（即尾部）移除1个元素并返回</li>
<li>LPUSHX/RPUSHX：与LPUSH/RPUSH类似，区别在于，LPUSHX/RPUSHX操作的key如果不存在，则不会进行任何操作</li>
<li>LLEN：返回指定List的长度，时间复杂度O(1)</li>
<li>LRANGE：返回指定List中指定范围的元素（双端包含，即LRANGE key 0 10会返回11个元素），时间复杂度O(N)。应尽可能控制一次获取的元素数量，一次获取过大范围的List元素会导致延迟，同时对长度不可预知的List，避免使用LRANGE key 0 -1这样的完整遍历操作。</li>
</ul>
<p>应谨慎使用的List相关命令：</p>
<ul>
<li>LINDEX：返回指定List指定index上的元素，如果index越界，返回nil。index数值是回环的，即-1代表List最后一个位置，-2代表List倒数第二个位置。时间复杂度O(N)</li>
<li>LSET：将指定List指定index上的元素设置为value，如果index越界则返回错误，时间复杂度O(N)，如果操作的是头/尾部的元素，则时间复杂度为O(1)</li>
<li>LINSERT：向指定List中指定元素之前/之后插入一个新元素，并返回操作后的List长度。如果指定的元素不存在，返回-1。如果指定key不存在，不会进行任何操作，时间复杂度O(N)</li>
</ul>
<p>由于Redis的List是链表结构的，上述的三个命令的算法效率较低，需要对List进行遍历，命令的耗时无法预估，在List长度大的情况下耗时会明显增加，应谨慎使用。</p>
<p>换句话说，Redis的List实际是设计来用于实现队列，而不是用于实现类似ArrayList这样的列表的。如果你不是想要实现一个双端出入的队列，那么请尽量不要使用Redis的List数据结构。</p>
<p>为了更好支持队列的特性，Redis还提供了一系列阻塞式的操作命令，如BLPOP/BRPOP等，能够实现类似于BlockingQueue的能力，即在List为空时，阻塞该连接，直到List中有对象可以出队时再返回。针对阻塞类的命令，此处不做详细探讨，请参考官方文档（https://redis.io/topics/data-types-intro） 中&quot;Blocking operations on lists&quot;一节。</p>
<p><strong>Hash</strong></p>
<p>Hash即哈希表，Redis的Hash和传统的哈希表一样，是一种field-value型的数据结构，可以理解成将HashMap搬入Redis。</p>
<p>Hash非常适合用于表现对象类型的数据，用Hash中的field对应对象的field即可。</p>
<p>Hash的优点包括：</p>
<ul>
<li>可以实现二元查找，如&quot;查找ID为1000的用户的年龄&quot;</li>
<li>比起将整个对象序列化后作为String存储的方法，Hash能够有效地减少网络传输的消耗</li>
<li>当使用Hash维护一个集合时，提供了比List效率高得多的随机访问命令</li>
</ul>
<p>与Hash相关的常用命令：</p>
<ul>
<li>HSET：将key对应的Hash中的field设置为value。如果该Hash不存在，会自动创建一个。时间复杂度O(1)</li>
<li>HGET：返回指定Hash中field字段的值，时间复杂度O(1)</li>
<li>HMSET/HMGET：同HSET和HGET，可以批量操作同一个key下的多个field，时间复杂度：O(N)，N为一次操作的field数量</li>
<li>HSETNX：同HSET，但如field已经存在，HSETNX不会进行任何操作，时间复杂度O(1)</li>
<li>HEXISTS：判断指定Hash中field是否存在，存在返回1，不存在返回0，时间复杂度O(1)</li>
<li>HDEL：删除指定Hash中的field（1个或多个），时间复杂度：O(N)，N为操作的field数量</li>
<li>HINCRBY：同INCRBY命令，对指定Hash中的一个field进行INCRBY，时间复杂度O(1)</li>
</ul>
<p>应谨慎使用的Hash相关命令：</p>
<ul>
<li>HGETALL：返回指定Hash中所有的field-value对。返回结果为数组，数组中field和value交替出现。时间复杂度O(N)</li>
<li>HKEYS/HVALS：返回指定Hash中所有的field/value，时间复杂度O(N)</li>
</ul>
<p>上述三个命令都会对Hash进行完整遍历，Hash中的field数量与命令的耗时线性相关，对于尺寸不可预知的Hash，应严格避免使用上面三个命令，而改为使用HSCAN命令进行游标式的遍历，具体请见 https://redis.io/commands/scan</p>
<p><strong>Set</strong></p>
<p>Redis Set是无序的，不可重复的String集合。</p>
<p>与Set相关的常用命令：</p>
<ul>
<li>SADD：向指定Set中添加1个或多个member，如果指定Set不存在，会自动创建一个。时间复杂度O(N)，N为添加的member个数</li>
<li>SREM：从指定Set中移除1个或多个member，时间复杂度O(N)，N为移除的member个数</li>
<li>SRANDMEMBER：从指定Set中随机返回1个或多个member，时间复杂度O(N)，N为返回的member个数</li>
<li>SPOP：从指定Set中随机移除并返回count个member，时间复杂度O(N)，N为移除的member个数</li>
<li>SCARD：返回指定Set中的member个数，时间复杂度O(1)</li>
<li>SISMEMBER：判断指定的value是否存在于指定Set中，时间复杂度O(1)</li>
<li>SMOVE：将指定member从一个Set移至另一个Set</li>
</ul>
<p>慎用的Set相关命令：</p>
<ul>
<li>SMEMBERS：返回指定Hash中所有的member，时间复杂度O(N)</li>
<li>SUNION/SUNIONSTORE：计算多个Set的并集并返回/存储至另一个Set中，时间复杂度O(N)，N为参与计算的所有集合的总member数</li>
<li>SINTER/SINTERSTORE：计算多个Set的交集并返回/存储至另一个Set中，时间复杂度O(N)，N为参与计算的所有集合的总member数</li>
<li>SDIFF/SDIFFSTORE：计算1个Set与1或多个Set的差集并返回/存储至另一个Set中，时间复杂度O(N)，N为参与计算的所有集合的总member数</li>
</ul>
<p>上述几个命令涉及的计算量大，应谨慎使用，特别是在参与计算的Set尺寸不可知的情况下，应严格避免使用。可以考虑通过SSCAN命令遍历获取相关Set的全部member（具体请见 https://redis.io/commands/scan ），如果需要做并集/交集/差集计算，可以在客户端进行，或在不服务实时查询请求的Slave上进行。</p>
<p><strong>Sorted Set</strong></p>
<p>Redis Sorted Set是有序的、不可重复的String集合。Sorted Set中的每个元素都需要指派一个分数(score)，Sorted Set会根据score对元素进行升序排序。如果多个member拥有相同的score，则以字典序进行升序排序。</p>
<p>Sorted Set非常适合用于实现排名。</p>
<p>Sorted Set的主要命令：</p>
<ul>
<li>ZADD：向指定Sorted Set中添加1个或多个member，时间复杂度O(Mlog(N))，M为添加的member数量，N为Sorted Set中的member数量</li>
<li>ZREM：从指定Sorted Set中删除1个或多个member，时间复杂度O(Mlog(N))，M为删除的member数量，N为Sorted Set中的member数量</li>
<li>ZCOUNT：返回指定Sorted Set中指定score范围内的member数量，时间复杂度：O(log(N))</li>
<li>ZCARD：返回指定Sorted Set中的member数量，时间复杂度O(1)</li>
<li>ZSCORE：返回指定Sorted Set中指定member的score，时间复杂度O(1)</li>
<li>ZRANK/ZREVRANK：返回指定member在Sorted Set中的排名，ZRANK返回按升序排序的排名，ZREVRANK则返回按降序排序的排名。时间复杂度O(log(N))</li>
<li>ZINCRBY：同INCRBY，对指定Sorted Set中的指定member的score进行自增，时间复杂度O(log(N))</li>
</ul>
<p>慎用的Sorted Set相关命令：</p>
<ul>
<li>ZRANGE/ZREVRANGE：返回指定Sorted Set中指定排名范围内的所有member，ZRANGE为按score升序排序，ZREVRANGE为按score降序排序，时间复杂度O(log(N)+M)，M为本次返回的member数</li>
<li>ZRANGEBYSCORE/ZREVRANGEBYSCORE：返回指定Sorted Set中指定score范围内的所有member，返回结果以升序/降序排序，min和max可以指定为-inf和+inf，代表返回所有的member。时间复杂度O(log(N)+M)</li>
<li>ZREMRANGEBYRANK/ZREMRANGEBYSCORE：移除Sorted Set中指定排名范围/指定score范围内的所有member。时间复杂度O(log(N)+M)</li>
</ul>
<p>上述几个命令，应尽量避免传递[0 -1]或[-inf +inf]这样的参数，来对Sorted Set做一次性的完整遍历，特别是在Sorted Set的尺寸不可预知的情况下。可以通过ZSCAN命令来进行游标式的遍历（具体请见 https://redis.io/commands/scan ），或通过LIMIT参数来限制返回member的数量（适用于ZRANGEBYSCORE和ZREVRANGEBYSCORE命令），以实现游标式的遍历。</p>
<p>Sorted Set的底层数据结构是: <a href="http://blog.csdn.net/acceptedxukai/article/details/17333673">跳跃表</a></p>
<p><strong>Bitmap和HyperLogLog</strong></p>
<p>Redis的这两种数据结构相较之前的并不常用，在本文中只做简要介绍，如想要详细了解这两种数据结构与其相关的命令，请参考官方文档https://redis.io/topics/data-types-intro 中的相关章节</p>
<p>Bitmap在Redis中不是一种实际的数据类型，而是一种将String作为Bitmap使用的方法。可以理解为将String转换为bit数组。使用Bitmap来存储true/false类型的简单数据极为节省空间。</p>
<p>HyperLogLogs是一种主要用于数量统计的数据结构，它和Set类似，维护一个不可重复的String集合，但是HyperLogLogs并不维护具体的member内容，只维护member的个数。也就是说，HyperLogLogs只能用于计算一个集合中不重复的元素数量，所以它比Set要节省很多内存空间。</p>
<p><strong>其他常用命令</strong></p>
<ul>
<li>EXISTS：判断指定的key是否存在，返回1代表存在，0代表不存在，时间复杂度O(1)</li>
<li>DEL：删除指定的key及其对应的value，时间复杂度O(N)，N为删除的key数量</li>
<li>EXPIRE/PEXPIRE：为一个key设置有效期，单位为秒或毫秒，时间复杂度O(1)</li>
<li>TTL/PTTL：返回一个key剩余的有效时间，单位为秒或毫秒，时间复杂度O(1)</li>
<li>RENAME/RENAMENX：将key重命名为newkey。使用RENAME时，如果newkey已经存在，其值会被覆盖；使用RENAMENX时，如果newkey已经存在，则不会进行任何操作，时间复杂度O(1)</li>
<li>TYPE：返回指定key的类型，string, list, set, zset, hash。时间复杂度O(1)</li>
<li>CONFIG GET：获得Redis某配置项的当前值，可以使用*通配符，时间复杂度O(1)</li>
<li>CONFIG SET：为Redis某个配置项设置新值，时间复杂度O(1)</li>
<li>CONFIG REWRITE：让Redis重新加载redis.conf中的配置</li>
</ul>
<h3 id="数据持久化">数据持久化</h3>
<p>Redis提供了将数据定期自动持久化至硬盘的能力，包括RDB和AOF两种方案，两种方案分别有其长处和短板，可以配合起来同时运行，确保数据的稳定性。</p>
<p><strong>必须使用数据持久化吗？</strong></p>
<p>Redis的数据持久化机制是可以关闭的。如果你只把Redis作为缓存服务使用，Redis中存储的所有数据都不是该数据的主体而仅仅是同步过来的备份，那么可以关闭Redis的数据持久化机制。<br>
但通常来说，仍然建议至少开启RDB方式的数据持久化，因为：</p>
<ul>
<li>RDB方式的持久化几乎不损耗Redis本身的性能，在进行RDB持久化时，Redis主进程唯一需要做的事情就是fork出一个子进程，所有持久化工作都由子进程完成</li>
<li>Redis无论因为什么原因crash掉之后，重启时能够自动恢复到上一次RDB快照中记录的数据。这省去了手工从其他数据源（如DB）同步数据的过程，而且要比其他任何的数据恢复方式都要快</li>
<li>现在硬盘那么大，真的不缺那一点地方</li>
</ul>
<h4 id="rdb">RDB</h4>
<p>采用RDB持久方式，Redis会定期保存数据快照至一个rbd文件中，并在启动时自动加载rdb文件，恢复之前保存的数据。可以在配置文件中配置Redis进行快照保存的时机：</p>
<pre><code>save [seconds] [changes]
</code></pre>
<p>意为在[seconds]秒内如果发生了[changes]次数据修改，则进行一次RDB快照保存，例如</p>
<pre><code>save 60 100
</code></pre>
<p>会让Redis每60秒检查一次数据变更情况，如果发生了100次或以上的数据变更，则进行RDB快照保存。<br>
可以配置多条save指令，让Redis执行多级的快照保存策略。<br>
Redis默认开启RDB快照，默认的RDB策略如下：</p>
<pre><code>save 900 1
save 300 10
save 60 10000
</code></pre>
<p>也可以通过BGSAVE命令手工触发RDB快照保存。</p>
<p><strong>RDB的优点：</strong></p>
<p>对性能影响最小。如前文所述，Redis在保存RDB快照时会fork出子进程进行，几乎不影响Redis处理客户端请求的效率。<br>
每次快照会生成一个完整的数据快照文件，所以可以辅以其他手段保存多个时间点的快照（例如把每天0点的快照备份至其他存储媒介中），作为非常可靠的灾难恢复手段。<br>
使用RDB文件进行数据恢复比使用AOF要快很多。</p>
<p><strong>RDB的缺点：</strong></p>
<p>快照是定期生成的，所以在Redis crash时或多或少会丢失一部分数据。<br>
如果数据集非常大且CPU不够强（比如单核CPU），Redis在fork子进程时可能会消耗相对较长的时间（长至1秒），影响这期间的客户端请求。</p>
<h4 id="aof">AOF</h4>
<p>采用AOF持久方式时，Redis会把每一个写请求都记录在一个日志文件里。在Redis重启时，会把AOF文件中记录的所有写操作顺序执行一遍，确保数据恢复到最新。</p>
<p>AOF默认是关闭的，如要开启，进行如下配置：</p>
<pre><code>appendonly yes
</code></pre>
<p>AOF提供了三种fsync配置，always/everysec/no，通过配置项[appendfsync]指定：</p>
<ul>
<li>appendfsync no：不进行fsync，将flush文件的时机交给OS决定，速度最快</li>
<li>appendfsync always：每写入一条日志就进行一次fsync操作，数据安全性最高，但速度最慢</li>
<li>appendfsync everysec：折中的做法，交由后台线程每秒fsync一次</li>
</ul>
<p>随着AOF不断地记录写操作日志，必定会出现一些无用的日志，例如某个时间点执行了命令SET key1 &quot;abc&quot;，在之后某个时间点又执行了SET key1 &quot;bcd&quot;，那么第一条命令很显然是没有用的。大量的无用日志会让AOF文件过大，也会让数据恢复的时间过长。<br>
所以Redis提供了AOF rewrite功能，可以重写AOF文件，只保留能够把数据恢复到最新状态的最小写操作集。<br>
AOF rewrite可以通过BGREWRITEAOF命令触发，也可以配置Redis定期自动进行：</p>
<pre><code>auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
</code></pre>
<p>上面两行配置的含义是，Redis在每次AOF rewrite时，会记录完成rewrite后的AOF日志大小，当AOF日志大小在该基础上增长了100%后，自动进行AOF rewrite。同时如果增长的大小没有达到64mb，则不会进行rewrite。</p>
<p><strong>AOF的优点：</strong></p>
<ul>
<li>最安全，在启用appendfsync always时，任何已写入的数据都不会丢失，使用在启用appendfsync everysec也至多只会丢失1秒的数据。</li>
<li>AOF文件在发生断电等问题时也不会损坏，即使出现了某条日志只写入了一半的情况，也可以使用redis-check-aof工具轻松修复。</li>
<li>AOF文件易读，可修改，在进行了某些错误的数据清除操作后，只要AOF文件没有rewrite，就可以把AOF文件备份出来，把错误的命令删除，然后恢复数据</li>
</ul>
<p><strong>AOF的缺点：</strong></p>
<ul>
<li>AOF文件通常比RDB文件更大</li>
<li>性能消耗比RDB高</li>
<li>数据恢复速度比RDB慢</li>
</ul>
<h3 id="内存管理与数据淘汰机制">内存管理与数据淘汰机制</h3>
<p><strong>最大内存设置</strong></p>
<p>默认情况下，在32位OS中，Redis最大使用3GB的内存，在64位OS中则没有限制。</p>
<p>在使用Redis时，应该对数据占用的最大空间有一个基本准确的预估，并为Redis设定最大使用的内存。否则在64位OS中Redis会无限制地占用内存（当物理内存被占满后会使用swap空间），容易引发各种各样的问题。</p>
<p>通过如下配置控制Redis使用的最大内存：</p>
<pre><code>maxmemory 100mb
</code></pre>
<p>在内存占用达到了maxmemory后，再向Redis写入数据时，Redis会：</p>
<ul>
<li>根据配置的数据淘汰策略尝试淘汰数据，释放空间</li>
<li>如果没有数据可以淘汰，或者没有配置数据淘汰策略，那么Redis会对所有写请求返回错误，但读请求仍然可以正常执行</li>
</ul>
<p>在为Redis设置maxmemory时，需要注意：</p>
<p>如果采用了Redis的主从同步，主节点向从节点同步数据时，会占用掉一部分内存空间，如果maxmemory过于接近主机的可用内存，导致数据同步时内存不足。所以设置的maxmemory不要过于接近主机可用的内存，留出一部分预留用作主从同步。</p>
<p><strong>数据淘汰机制</strong></p>
<p>Redis提供了六种数据淘汰策略：</p>
<ul>
<li>volatile-lru：使用LRU算法进行数据淘汰（淘汰上次使用时间最早的，且使用次数最少的key），只淘汰设定了有效期的key</li>
<li>allkeys-lru：使用LRU算法进行数据淘汰，所有的key都可以被淘汰</li>
<li>volatile-random：随机淘汰数据，只淘汰设定了有效期的key</li>
<li>allkeys-random：随机淘汰数据，所有的key都可以被淘汰</li>
<li>volatile-ttl：淘汰剩余有效期最短的key</li>
<li>noeviction：当内存使用达到阈值的时候，所有引起申请内存的命令会报错</li>
</ul>
<p>最好为Redis指定一种有效的数据淘汰策略以配合maxmemory设置，避免在内存使用满后发生写入失败的情况。</p>
<p>一般来说，推荐使用的策略是volatile-lru，并辨识Redis中保存的数据的重要性。对于那些重要的，绝对不能丢弃的数据（如配置类数据等），应不设置有效期，这样Redis就永远不会淘汰这些数据。对于那些相对不是那么重要的，并且能够热加载的数据（比如缓存最近登录的用户信息，当在Redis中找不到时，程序会去DB中读取），可以设置上有效期，这样在内存不够时Redis就会淘汰这部分数据。</p>
<p>配置方法：</p>
<pre><code>maxmemory-policy volatile-lru   #默认是noeviction，即不进行数据淘汰
</code></pre>
<h3 id="pipelining">Pipelining</h3>
<p>edis提供许多批量操作的命令，如MSET/MGET/HMSET/HMGET等等，这些命令存在的意义是减少维护网络连接和传输数据所消耗的资源和时间。<br>
例如连续使用5次SET命令设置5个不同的key，比起使用一次MSET命令设置5个不同的key，效果是一样的，但前者会消耗更多的RTT(Round Trip Time)时长，永远应优先使用后者。</p>
<p>然而，如果客户端要连续执行的多次操作无法通过Redis命令组合在一起，例如：</p>
<pre><code>SET a &quot;abc&quot;
INCR b
HSET c name &quot;hi&quot;
</code></pre>
<p>此时便可以使用Redis提供的pipelining功能来实现在一次交互中执行多条命令。<br>
使用pipelining时，只需要从客户端一次向Redis发送多条命令（以\r\n）分隔，Redis就会依次执行这些命令，并且把每个命令的返回按顺序组装在一起一次返回，比如：</p>
<pre><code>$ (printf &quot;PING\r\nPING\r\nPING\r\n&quot;; sleep 1) | nc localhost 6379
+PONG
+PONG
+PONG
</code></pre>
<p>大部分的Redis客户端都对Pipelining提供支持，所以开发者通常并不需要自己手工拼装命令列表</p>
<p><strong>Pipelining的局限性</strong></p>
<p>Pipelining只能用于执行连续且无相关性的命令，当某个命令的生成需要依赖于前一个命令的返回时，就无法使用Pipelining了。</p>
<p>通过Scripting功能，可以规避这一局限性</p>
<h3 id="事务与scripting">事务与Scripting</h3>
<p><strong>Pipelining</strong></p>
<p>Pipelining能够让Redis在一次交互中处理多条命令，然而在一些场景下，我们可能需要在此基础上确保这一组命令是连续执行的。</p>
<p>比如获取当前累计的PV数并将其清0</p>
<pre><code>&gt; GET vCount
12384
&gt; SET vCount 0
OK
</code></pre>
<p>如果在GET和SET命令之间插进来一个INCR vCount，就会使客户端拿到的vCount不准确。</p>
<p>Redis的事务可以确保复数命令执行时的原子性。也就是说Redis能够保证：一个事务中的一组命令是绝对连续执行的，在这些命令执行完成之前，绝对不会有来自于其他连接的其他命令插进去执行。</p>
<p>通过MULTI和EXEC命令来把这两个命令加入一个事务中：</p>
<pre><code>&gt; MULTI
OK
&gt; GET vCount
QUEUED
&gt; SET vCount 0
QUEUED
&gt; EXEC
1) 12384
2) OK
</code></pre>
<p>Redis在接收到MULTI命令后便会开启一个事务，这之后的所有读写命令都会保存在队列中但并不执行，直到接收到EXEC命令后，Redis会把队列中的所有命令连续顺序执行，并以数组形式返回每个命令的返回结果。</p>
<p>可以使用DISCARD命令放弃当前的事务，将保存的命令队列清空。</p>
<p>需要注意的是，Redis事务不支持回滚：</p>
<p>如果一个事务中的命令出现了语法错误，大部分客户端驱动会返回错误，2.6.5版本以上的Redis也会在执行EXEC时检查队列中的命令是否存在语法错误，如果存在，则会自动放弃事务并返回错误。<br>
但如果一个事务中的命令有非语法类的错误（比如对String执行HSET操作），无论客户端驱动还是Redis都无法在真正执行这条命令之前发现，所以事务中的所有命令仍然会被依次执行。在这种情况下，会出现一个事务中部分命令成功部分命令失败的情况，然而与RDBMS不同，Redis不提供事务回滚的功能，所以只能通过其他方法进行数据的回滚。</p>
<h3 id="通过事务实现cas">通过事务实现CAS</h3>
<p>Redis提供了WATCH命令与事务搭配使用，实现CAS乐观锁的机制。</p>
<p>假设要实现将某个商品的状态改为已售：</p>
<pre><code>if(exec(HGET stock:1001 state) == &quot;in stock&quot;)
    exec(HSET stock:1001 state &quot;sold&quot;);
</code></pre>
<p>这一伪代码执行时，无法确保并发安全性，有可能多个客户端都获取到了&quot;in stock&quot;的状态，导致一个库存被售卖多次。</p>
<p>使用WATCH命令和事务可以解决这一问题：</p>
<pre><code>exec(WATCH stock:1001);
if(exec(HGET stock:1001 state) == &quot;in stock&quot;) {
    exec(MULTI);
    exec(HSET stock:1001 state &quot;sold&quot;);
    exec(EXEC);
}
</code></pre>
<p>WATCH的机制是：在事务EXEC命令执行时，Redis会检查被WATCH的key，只有被WATCH的key从WATCH起始时至今没有发生过变更，EXEC才会被执行。如果WATCH的key在WATCH命令到EXEC命令之间发生过变化，则EXEC命令会返回失败。</p>
<p><strong>Scripting</strong></p>
<p>通过EVAL与EVALSHA命令，可以让Redis执行LUA脚本。这就类似于RDBMS的存储过程一样，可以把客户端与Redis之间密集的读/写交互放在服务端进行，避免过多的数据交互，提升性能。</p>
<p>Scripting功能是作为事务功能的替代者诞生的，事务提供的所有能力Scripting都可以做到。Redis官方推荐使用LUA Script来代替事务，前者的效率和便利性都超过了事务。</p>
<p>关于Scripting的具体使用，本文不做详细介绍，请参考官方文档 https://redis.io/commands/eval</p>
<h2 id="redis性能调优">Redis性能调优</h2>
<p>尽管Redis是一个非常快速的内存数据存储媒介，也并不代表Redis不会产生性能问题。<br>
前文中提到过，Redis采用单线程模型，所有的命令都是由一个线程串行执行的，所以当某个命令执行耗时较长时，会拖慢其后的所有命令，这使得Redis对每个任务的执行效率更加敏感。</p>
<p>针对Redis的性能优化，主要从下面几个层面入手：</p>
<ul>
<li>最初的也是最重要的，确保没有让Redis执行耗时长的命令</li>
<li>使用pipelining将连续执行的命令组合执行</li>
<li>操作系统的Transparent huge pages功能必须关闭：echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</li>
<li>如果在虚拟机中运行Redis，可能天然就有虚拟机环境带来的固有延迟。可以通过./redis-cli --intrinsic-latency 100命令查看固有延迟。同时如果对Redis的性能有较高要求的话，应尽可能在物理机上直接部署Redis。</li>
<li>检查数据持久化策略</li>
<li>考虑引入读写分离机制</li>
</ul>
<p><strong>长耗时命令</strong></p>
<p>Redis绝大多数读写命令的时间复杂度都在O(1)到O(N)之间，在文本和官方文档中均对每个命令的时间复杂度有说明。</p>
<p>通常来说，O(1)的命令是安全的，O(N)命令在使用时需要注意，如果N的数量级不可预知，则应避免使用。例如对一个field数未知的Hash数据执行HGETALL/HKEYS/HVALS命令，通常来说这些命令执行的很快，但如果这个Hash中的field数量极多，耗时就会成倍增长。<br>
又如使用SUNION对两个Set执行Union操作，或使用SORT对List/Set执行排序操作等时，都应该严加注意。</p>
<p>避免在使用这些O(N)命令时发生问题主要有几个办法：</p>
<ul>
<li>不要把List当做列表使用，仅当做队列来使用</li>
<li>通过机制严格控制Hash、Set、Sorted Set的大小</li>
<li>可能的话，将排序、并集、交集等操作放在客户端执行</li>
<li>绝对禁止使用KEYS命令</li>
<li>避免一次性遍历集合类型的所有成员，而应使用SCAN类的命令进行分批的，游标式的遍历</li>
</ul>
<p>Redis提供了SCAN命令，可以对Redis中存储的所有key进行游标式的遍历，避免使用KEYS命令带来的性能问题。同时还有SSCAN/HSCAN/ZSCAN等命令，分别用于对Set/Hash/Sorted Set中的元素进行游标式遍历。</p>
<p>Redis提供了Slow Log功能，可以自动记录耗时较长的命令。相关的配置参数有两个：</p>
<pre><code>slowlog-log-slower-than xxxms  #执行时间慢于xxx毫秒的命令计入Slow Log
slowlog-max-len xxx  #Slow Log的长度，即最大纪录多少条Slow Log
</code></pre>
<p><strong>网络引发的延迟</strong></p>
<ul>
<li>尽可能使用长连接或连接池，避免频繁创建销毁连接</li>
<li>客户端进行的批量数据操作，应使用Pipeline特性在一次交互中完成。具体请参照本文的Pipelining章节</li>
</ul>
<p><strong>数据持久化引发的延迟</strong></p>
<p>Redis的数据持久化工作本身就会带来延迟，需要根据数据的安全级别和性能要求制定合理的持久化策略：</p>
<ul>
<li>AOF + fsync always的设置虽然能够绝对确保数据安全，但每个操作都会触发一次fsync，会对Redis的性能有比较明显的影响</li>
<li>AOF + fsync every second是比较好的折中方案，每秒fsync一次</li>
<li>AOF + fsync never会提供AOF持久化方案下的最优性能</li>
<li>使用RDB持久化通常会提供比使用AOF更高的性能，但需要注意RDB的策略配置</li>
<li>每一次RDB快照和AOF Rewrite都需要Redis主进程进行fork操作。fork操作本身可能会产生较高的耗时，与CPU和Redis占用的内存大小有关。根据具体的情况合理配置RDB快照和AOF Rewrite时机，避免过于频繁的fork带来的延迟</li>
</ul>
<p><strong>Swap引发的延迟</strong></p>
<p>当Linux将Redis所用的内存分页移至swap空间时，将会阻塞Redis进程，导致Redis出现不正常的延迟。Swap通常在物理内存不足或一些进程在进行大量I/O操作时发生，应尽可能避免上述两种情况的出现。</p>
<p>/proc/<pid>/smaps文件中会保存进程的swap记录，通过查看这个文件，能够判断Redis的延迟是否由Swap产生。如果这个文件中记录了较大的Swap size，则说明延迟很有可能是Swap造成的。</p>
<p><strong>数据淘汰引发的延迟</strong></p>
<p>当同一秒内有大量key过期时，也会引发Redis的延迟。在使用时应尽量将key的失效时间错开。</p>
<p><strong>引入读写分离机制</strong></p>
<p>Redis的主从复制能力可以实现一主多从的多节点架构，在这一架构下，主节点接收所有写请求，并将数据同步给多个从节点。<br>
在这一基础上，我们可以让从节点提供对实时性要求不高的读请求服务，以减小主节点的压力。<br>
尤其是针对一些使用了长耗时命令的统计类任务，完全可以指定在一个或多个从节点上执行，避免这些长耗时命令影响其他请求的响应</p>
<h2 id="集群redis-cluster-codis">集群—redis cluster、codis</h2>
<p>我们日常在对于redis的使用中，经常会遇到一些问题</p>
<ol>
<li>高可用问题，如何保证redis的持续高可用性。</li>
<li>容量问题，单实例redis内存无法无限扩充，达到32G后就进入了64位世界，性能下降。</li>
<li>并发性能问题，redis号称单实例10万并发，但也是有尽头的。</li>
</ol>
<h3 id="codis">codis</h3>
<p>Codis 是一个分布式 Redis 解决方案, 对于上层的应用来说, 连接到 Codis Proxy 和连接原生的 Redis Server 没有明显的区别 (不支持的命令列表), 上层应用可以像使用单机的 Redis 一样使用, Codis 底层会处理请求的转发, 不停机的数据迁移等工作, 所有后边的一切事情, 对于前面的客户端来说是透明的, 可以简单的认为后边连接的是一个内存无限大的 Redis 服务.</p>
<p><strong>组成部分</strong></p>
<ul>
<li>Codis Proxy (codis-proxy)</li>
<li>Codis Manager (codis-config)</li>
<li>Codis Redis (codis-server)</li>
<li>ZooKeeper</li>
</ul>
<p>codis-proxy 是客户端连接的 Redis 代理服务, codis-proxy 本身实现了 Redis 协议, 表现得和一个原生的 Redis 没什么区别 (就像 Twemproxy), 对于一个业务来说, 可以部署多个 codis-proxy, codis-proxy 本身是无状态的.</p>
<p>codis-config 是 Codis 的管理工具, 支持包括, 添加/删除 Redis 节点, 添加/删除 Proxy 节点, 发起数据迁移等操作. codis-config 本身还自带了一个 http server, 会启动一个 dashboard, 用户可以直接在浏览器上观察 Codis 集群的运行状态.</p>
<p>codis-server 是 Codis 项目维护的一个 Redis 分支, 基于 2.8.13 开发, 加入了 slot 的支持和原子的数据迁移指令. Codis 上层的 codis-proxy 和 codis-config 只能和这个版本的 Redis 交互才能正常运行.</p>
<p>Codis 依赖 ZooKeeper 来存放数据路由表和 codis-proxy 节点的元信息, codis-config 发起的命令都会通过 ZooKeeper 同步到各个存活的 codis-proxy.</p>
<p>Codis 支持按照 Namespace 区分不同的产品, 拥有不同的 product name 的产品, 各项配置都不会冲突</p>
<p><strong>特性</strong></p>
<ul>
<li>自动平衡</li>
<li>使用非常简单</li>
<li>图形化的面板和管理工具</li>
<li>支持绝大多数 Redis 命令，完全兼容twemproxy</li>
<li>支持 Redis 原生客户端</li>
<li>安全而且透明的数据移植，可根据需要轻松添加和删除节点</li>
<li>提供命令行接口</li>
<li>RESTful APIs</li>
</ul>
<h3 id="redis-cluster">redis-cluster</h3>
<p>Redis Cluster是Redis的分布式解决方案，在Redis 3.0版本正式推出的，有效解决了Redis分布式方面的需求。当遇到单机内存、并发、流量等瓶颈时，可以采用Cluster架构达到负载均衡的目的。</p>
<p><strong>数据分布理论</strong></p>
<p>分布式数据库首要解决把整个数据集按照分区规则映射到多个节点的问题，即把数据集划分到多个节点上，每个节点负责整个数据的一个子集。常见的分区规则有哈希分区和顺序分区。Redis Cluster采用哈希分区规则，因此接下来会讨论哈希分区规则。</p>
<p>常见的哈希分区有以下几种:</p>
<ul>
<li>节点取余分区</li>
<li>一致性哈希分区</li>
<li>虚拟槽分区</li>
</ul>
<p>Redis Cluster采用虚拟槽分区，因此先介绍一下虚拟槽分区。</p>
<p>虚拟槽分区巧妙地使用了哈希空间，使用分散度良好的哈希函数把所有的数据映射到一个固定范围内的整数集合，整数定义为槽（slot）。比如Redis Cluster槽的范围是0 ～ 16383。槽是集群内数据管理和迁移的基本单位。采用大范围的槽的主要目的是为了方便数据的拆分和集群的扩展，每个节点负责一定数量的槽。</p>
<p><strong>Redis 数据分区</strong></p>
<p>Redis Cluster采用虚拟槽分区，所有的键根据哈希函数映射到0 ～ 16383，计算公式：slot = CRC16(key)&amp;16383。每一个节点负责维护一部分槽以及槽所映射的键值数据。</p>
<p>下图展现一个五个节点构成的集群，每个节点平均大约负责3276个槽，以及通过计算公式映射到对应节点的对应槽的过程。</p>
<figure data-type="image" tabindex="1"><img src="http://img.blog.csdn.net/20170603165614671?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbWVuX3dlbg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="" loading="lazy"></figure>
<p><strong>Redis 集群功能限制</strong></p>
<p>Redis集群相对单机在功能上有一定限制:</p>
<ul>
<li>key批量操作支持有限。如：MSET``MGET，目前只支持具有相同slot值的key执行批量操作</li>
<li>key事务操作支持有限。支持多key在同一节点上的事务操作，不支持分布在多个节点的事务功能。</li>
<li>key作为数据分区的最小粒度，因此不能将一个大的键值对象映射到不同的节点。如：hash、list</li>
<li>不支持多数据库空间。单机下Redis支持16个数据库，集群模式下只能使用一个数据库空间，即db 0</li>
<li>复制结构只支持一层，不支持嵌套树状复制结构</li>
</ul>
<p>另外还有阿里云的redis集群,关于种集群的对比: 参考: <a href="https://yq.aliyun.com/articles/68593?utm_campaign=wenzhang&amp;utm_medium=article&amp;utm_source=QQ-qun&amp;utm_content=m_10099">redis4.0、codis、阿里云redis 3种redis集群对比分析</a></p>
<h2 id="参考">参考</h2>
<ul>
<li><a href="https://www.cnblogs.com/276815076/p/7245333.html">Redis基础、高级特性与性能调优</a></li>
<li><a href="http://xiaorui.cc/2015/03/27/redis%E7%9A%84sorted-set%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84skip-list%E8%B7%B3%E8%B7%83%E8%A1%A8/">折腾redis的sorted set数据结构Skip List跳跃表</a></li>
<li><a href="http://blog.csdn.net/odailidong/article/details/52782753">Redis 为什么用跳表而不用平衡树？</a></li>
<li><a href="https://www.zhihu.com/question/30857837">redis cluster及codis之间该如何选择？</a></li>
<li><a href="https://yq.aliyun.com/articles/68593?utm_campaign=wenzhang&amp;utm_medium=article&amp;utm_source=QQ-qun&amp;utm_content=m_10099">redis4.0、codis、阿里云redis 3种redis集群对比分析</a></li>
</ul>
<h2 id="阅读书籍">阅读书籍</h2>
<ul>
<li><a href="https://book.douban.com/subject/26612779/">Redis实战</a></li>
</ul>

              </div>
              <div class="toc-container">
                <ul class="markdownIt-TOC">
<li>
<ul>
<li><a href="#%E5%89%8D%E8%A8%80">前言</a></li>
<li><a href="#%E7%9B%AE%E5%BD%95">目录</a>
<ul>
<li><a href="#%E6%A6%82%E8%BF%B0">概述</a></li>
<li><a href="#redis%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%9B%B8%E5%85%B3%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4">Redis的数据结构和相关常用命令</a></li>
<li><a href="#%E6%95%B0%E6%8D%AE%E6%8C%81%E4%B9%85%E5%8C%96">数据持久化</a>
<ul>
<li><a href="#rdb">RDB</a></li>
<li><a href="#aof">AOF</a></li>
</ul>
</li>
<li><a href="#%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%B7%98%E6%B1%B0%E6%9C%BA%E5%88%B6">内存管理与数据淘汰机制</a></li>
<li><a href="#pipelining">Pipelining</a></li>
<li><a href="#%E4%BA%8B%E5%8A%A1%E4%B8%8Escripting">事务与Scripting</a></li>
<li><a href="#%E9%80%9A%E8%BF%87%E4%BA%8B%E5%8A%A1%E5%AE%9E%E7%8E%B0cas">通过事务实现CAS</a></li>
</ul>
</li>
<li><a href="#redis%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98">Redis性能调优</a></li>
<li><a href="#%E9%9B%86%E7%BE%A4redis-cluster-codis">集群—redis cluster、codis</a>
<ul>
<li><a href="#codis">codis</a></li>
<li><a href="#redis-cluster">redis-cluster</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83">参考</a></li>
<li><a href="#%E9%98%85%E8%AF%BB%E4%B9%A6%E7%B1%8D">阅读书籍</a></li>
</ul>
</li>
</ul>

              </div>
            </div>
          </article>
        </div>

        
          <div class="next-post">
            <div class="next">下一篇</div>
            <a href="https://www.felayman.com/post/2015-nian-du-shou-cang-hao-wen/">
              <h3 class="post-title">
                2015年度收藏好文
              </h3>
            </a>
          </div>
        

        

        <div class="site-footer">
  
  <a class="rss" href="https://www.felayman.com/atom.xml" target="_blank">
    <i class="ri-rss-line"></i> RSS
  </a>
</div>

      </div>
    </div>

    <script>
      hljs.initHighlightingOnLoad()

      let mainNavLinks = document.querySelectorAll(".markdownIt-TOC a");

      // This should probably be throttled.
      // Especially because it triggers during smooth scrolling.
      // https://lodash.com/docs/4.17.10#throttle
      // You could do like...
      // window.addEventListener("scroll", () => {
      //    _.throttle(doThatStuff, 100);
      // });
      // Only not doing it here to keep this Pen dependency-free.

      window.addEventListener("scroll", event => {
        let fromTop = window.scrollY;

        mainNavLinks.forEach((link, index) => {
          let section = document.getElementById(decodeURI(link.hash).substring(1));
          let nextSection = null
          if (mainNavLinks[index + 1]) {
            nextSection = document.getElementById(decodeURI(mainNavLinks[index + 1].hash).substring(1));
          }
          if (section.offsetTop <= fromTop) {
            if (nextSection) {
              if (nextSection.offsetTop > fromTop) {
                link.classList.add("current");
              } else {
                link.classList.remove("current");    
              }
            } else {
              link.classList.add("current");
            }
          } else {
            link.classList.remove("current");
          }
        });
      });

    </script>
  </body>
</html>
